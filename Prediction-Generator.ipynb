{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb6855e-6d4a-4e68-b32a-f9d099c6f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "## Modules to check the performance of the code\n",
    "from time import process_time \n",
    "# !pip install memory_profiler ## When running from Google Colab\n",
    "# import memory_profiler as mem_profile\n",
    "# print('Memory (Before): {}Mb'.format(mem_profile.memory_usage()))\n",
    "\n",
    "\n",
    "## Importing the necessary TesnorFLow modules modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "# mlcompute.set_mlc_device(device_name='gpu')\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import r2_score ## form calcualting the r2 score\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras as k\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "## Trasfer Learning Models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1 \n",
    "from tensorflow.keras.applications import EfficientNetB2, EfficientNetB3\n",
    "from tensorflow.keras.applications import EfficientNetB4, EfficientNetB5 \n",
    "from tensorflow.keras.applications import EfficientNetB6, EfficientNetB7\n",
    "from tensorflow.keras.applications import ResNet50,ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8936ad53-e698-46ea-9261-b7e81059e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Please provide the same path to the code directory if using Colab################\n",
    "\n",
    "# Path_gdrive= '/content/drive/MyDrive/DPNNet-RT/' ## Comment out this line if using local computer\n",
    "\n",
    "## Importing the Modules from Modules_DPNNet\n",
    "import sys\n",
    "try: ## tries to find the modules in the local directory first\n",
    "  current_directory = os.getcwd()\n",
    "  path = current_directory + '/' # For local computer \n",
    "#   path = '' # For local computer  \n",
    "  sys.path.append(path+'MODULES_DPNNeT')\n",
    "  import data_processing_RT as dp\n",
    "  import deep_models as dm\n",
    "  import other_cnns as ocn\n",
    "\n",
    "########### Folders to save the processed data, files and figures when using Local computer ##############\n",
    "  output_folder_list = ['data_folder','figures','saved_model']\n",
    "  for file in output_folder_list:\n",
    "    try:\n",
    "        os.makedirs(file)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed/ not needed as it already exit\" % file)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s\" % file)\n",
    "  \n",
    "except ModuleNotFoundError:\n",
    "  \n",
    "  # #For Colab use:\n",
    "  # #Point to the path containing the modules in the above section\n",
    "  #(data folder are a directory above the directory containing the notebook)\n",
    "  try:\n",
    "    path = Path_gdrive\n",
    "    print(path)\n",
    "    sys.path.append(path+'MODULES_DPNNeT')\n",
    "    import data_processing_RT as dp\n",
    "    import deep_models as dm\n",
    "    import other_cnns as ocn\n",
    "\n",
    "    ########### Folders to save the processed data, files and figures when using GDRIVE ##############\n",
    "    import os\n",
    "    os.chdir(path)\n",
    "    print(\"Creating the folders\")\n",
    "    !mkdir -p data_folder\n",
    "    !mkdir -p figures ## to save the figures\n",
    "    !mkdir -p figures_paper\n",
    "    !mkdir -p saved_model\n",
    "  except ModuleNotFoundError:\n",
    "    print(\"The path to the modules is incorrect-- Provide current path\")\n",
    "\n",
    "print(\"[INFO] Modules imported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff80f37-4dce-455e-995a-6d2463bb2bf8",
   "metadata": {},
   "source": [
    "# Model Selections and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f5adb-9db6-482b-8500-8986f529255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Desired Image resoltuion  and Batch Size #####\n",
    "X_res = Y_res = 128\n",
    "\n",
    "\n",
    "## Select the kind of Traning ## Both can be selected as well\n",
    "REG = True #True  ## When choosing regression\n",
    "CLA = False #False #False #True  ## When Choosing Clasiffication\n",
    "\n",
    "\n",
    "## Select the Network type\n",
    "\n",
    "# NETWORK = \"Vanilla\" ## Cannot be uses at the moment\n",
    "# NETWORK = \"ALEXNET\"\n",
    "# NETWORK = \"VGG\"\n",
    "# NETWORK = \"RESNET50\"\n",
    "\n",
    "                                ########## When using Trasnfer Learning ######################\n",
    "NETWORK = \"TL\"\n",
    "transfer_model=ResNet50\n",
    "# transfer_model=EfficientNetB3\n",
    "\n",
    "## Hyper-Parameter to define\n",
    "batch_size = 50 ## 20 was for regression ## the best was for 200 last run\n",
    "\n",
    "# early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.2, patience=20, verbose=1, mode='min',restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd03d5-7fb0-4b04-916b-9544350b75dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data_folder/test_dataset.csv\")\n",
    "train = pd.read_csv(\"data_folder/train_dataset.csv\")\n",
    "## Generate the Normalized data\n",
    "normed_train_data, normed_test_data, train_labels, test_labels = dp.process_the_disk_attributes(train, test, path,multi_label=True)\n",
    "\n",
    "if CLA == True:\n",
    "        ### Preparing the dataset for the classification problem--- \n",
    "        ## For classification we included binary 1 or 0 depending on if the planet is present or not respectively\n",
    "        train['Planet_Mass1'] = np.where(train['Planet_Mass1']!= 0, 1,0)\n",
    "        train['Planet_Mass2'] = np.where(train['Planet_Mass2']!= 0, 1,0)\n",
    "        train['Planet_Mass3'] = np.where(train['Planet_Mass3']!= 0, 1,0)\n",
    "        # train = train.select_dtypes(\"string\")\n",
    "        test['Planet_Mass1'] = np.where(test['Planet_Mass1']!= 0, 1, 0)\n",
    "        test['Planet_Mass2'] = np.where(test['Planet_Mass2']!= 0, 1, 0)\n",
    "        test['Planet_Mass3'] = np.where(test['Planet_Mass3']!= 0, 1, 0)\n",
    "        \n",
    "        Y_train=train[['Planet_Mass1','Planet_Mass2','Planet_Mass3']] ## These are used as label for the non-generator training\n",
    "        Y_test=test[['Planet_Mass1','Planet_Mass2','Planet_Mass3']]\n",
    "        \n",
    "\n",
    "def custom_augmentation(np_tensor):\n",
    "\n",
    "    '''\n",
    "    This function is used to crop the images when those are loaded using the \n",
    "    ImageDataGenerator Keras function. This custom augmentation function only\n",
    "    works for three different res as given below. For other resolutions the \n",
    "    image needs to the cropped appropiately.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # # # dimensions for cropping the image\n",
    "    if X_res == 128:\n",
    "      top,left,bottom,right = 20,25,110,90 \n",
    "    if X_res == 256:          \n",
    "      top,left,bottom,right = 40,50,220,180          \n",
    "    if X_res == 512:\n",
    "      top,left,bottom,right = 60,90,450,380          \n",
    "\n",
    "    image = np.squeeze(np_tensor) \n",
    "    crop_image = image[top:bottom, left:right]\n",
    "    crop_image = cv2.resize(crop_image, (X_res, Y_res)) \n",
    "    crop_image = k.preprocessing.image.img_to_array(crop_image)\n",
    "    return crop_image\n",
    "\n",
    "\n",
    "datagen= ImageDataGenerator(preprocessing_function=custom_augmentation,rescale=1./255.,validation_split=0.15)\n",
    "\n",
    "#### TESTING GENERATOR #####\n",
    "test_datagen= k.preprocessing.image.ImageDataGenerator(preprocessing_function=custom_augmentation,rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test,\n",
    "directory=None,\n",
    "x_col=\"image_path\",\n",
    "y_col=[\"Planet_Mass1\",'Planet_Mass2','Planet_Mass3'],\n",
    "batch_size=batch_size,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(X_res,Y_res))\n",
    "\n",
    "if X_res < 128:\n",
    "    testImagesX = dp.load_disk_images(test, X_res, Y_res, Type = \"Test\")\n",
    "\n",
    "## STEP SIZES later used for training using generators\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c046e2-ffdf-43e2-887b-3ddc6caafd8f",
   "metadata": {},
   "source": [
    "## Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff91cf-66b5-4da6-bed3-dff49e136b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "\n",
    "if NETWORK == \"TL\":\n",
    "    if REG == True and CLA == True:\n",
    "        CNN = tf.keras.models.load_model(path+'saved_model/'+NETWORK+'_'+str( transfer_model.__name__)+'_'+str(X_res)+'_modelRC')\n",
    "    elif REG == True:\n",
    "        CNN = tf.keras.models.load_model(path+'saved_model/'+NETWORK+'_'+str( transfer_model.__name__)+'_'+str(X_res)+'_modelR')\n",
    "    elif CLA == True:\n",
    "        CNN = tf.keras.models.load_model(path+'saved_model/'+NETWORK+'_'+str( transfer_model.__name__)+'_'+str(X_res)+'_modelC')\n",
    "        \n",
    "    print(\"INFO:The Trained model {} at res {} is loaded \".format(NETWORK+'_'+str( transfer_model.__name__),str(X_res)))\n",
    "else:\n",
    "    if REG == True and CLA == True:\n",
    "        CNN = tf.keras.models.load_model(path+'saved_model/'+NETWORK+'_'+str(X_res)+'_modelRC')\n",
    "    elif REG == True:\n",
    "        CNN = tf.keras.models.load_model(path+'saved_model/'+NETWORK+'_'+str(X_res)+'_modelR')\n",
    "    elif CLA == True:\n",
    "        CNN = tf.keras.models.load_model(path+'saved_model/'+NETWORK+'_'+str(X_res)+'_modelC')\n",
    "\n",
    "\n",
    "\n",
    "# CNN = tf.keras.models.load_model(path+'saved_model/'+NETWORK+'_'+str(X_res)+'_modelRC')\n",
    "#Check its architecture\n",
    "# CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9159b19-b6aa-4144-a684-a09ca23b75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if X_res >= 128:\n",
    "\n",
    "    test_generator.reset()\n",
    "    pred_CNN=CNN.predict_generator(test_generator,\n",
    "    steps=STEP_SIZE_TEST,\n",
    "    verbose=1)\n",
    "else:\n",
    "    \n",
    "    pred_CNN = CNN.predict(testImagesX)  \n",
    "# pred_CNN[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5d9da-d666-4c16-82a7-7cda864f0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 41 # 550  #550 ##210\n",
    "# plt.imshow(testImagesX[test_iclass_mode)\n",
    "if REG == True:\n",
    "    print(\"The predicted Values are {} and \\nThe True values are \\n{} \".format(pred_CNN[test_index],test_labels.iloc[test_index]))\n",
    "elif CLA == True:\n",
    "    print(\"The predicted prbability of the presence of planets are {} and \\nThe True values are \\n{} \".format(pred_CNN[test_index],Y_test.iloc[test_index]))\n",
    "    print(\"The predicted Values are {} and \\nThe True values are \\n{} \".format(pred_CNN[test_index],test_labels.iloc[test_index]))\n",
    "\n",
    "# plt.imshow(testImagesX[test_index])\n",
    "# test_labels.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cb3e6-92fd-4251-8f86-7870a97228d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('classic')\n",
    "plt.figure(figsize = (5,5))\n",
    "# test_predictions = model.predict(normed_test_data).flatten()\n",
    "plt.scatter(test_labels.to_numpy().flatten(),pred_CNN.flatten(),s=15,marker='d',color='r')\n",
    "score_CNN = r2_score(test_labels.to_numpy().flatten(),pred_CNN.flatten())\n",
    "plt.text(20,880,r\" r2 = {:.3f}\".format(score_CNN), fontsize =14)\n",
    "plt.xlabel(r'True values of planet mass($M_\\oplus$)', fontsize=15)\n",
    "plt.ylabel(r'Predicted planet mass($M_\\oplus$)',fontsize=15)\n",
    "plt.title(\"{} Prediction\".format(NETWORK))\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim(10,1000)\n",
    "plt.ylim(10,1000)\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xscale('log')\n",
    "# plt.xlim([0.6,plt.xlim()[1]])\n",
    "# plt.ylim([0.6,plt.xlim()[1]])\n",
    "_ = plt.plot([0, 1200], [0, 1200],linewidth=2)\n",
    "plt.minorticks_on() \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(path+'figures_paper/predicted_correlation_{}.pdf'.format(NETWORK),format='pdf',dpi=300)\n",
    "\n",
    "# np.shape(pred_CNN.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530e281-86dc-4230-a641-9821d705823f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env_2",
   "language": "python",
   "name": "ml_env_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
